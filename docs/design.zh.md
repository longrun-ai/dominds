# Dominds：AI 智能体的社会分工

英文版：[English](./design.md)

## 概述

Dominds 为 AI 智能体实现了**社会分工**——一种通过战略性心理清晰实践来管理认知过载的系统性方法。本文档概述了我们防止智能体迷失方向和在 AI-人协作环境中保持高效专注的综合框架。

**核心问题**：LLM 智能体很容易迷失方向，远在技术上下文窗口完全填满之前。问题从来不是 token 太多，而是方面和关注点太多——它们像人类一样遭受心理过载。

**关键设计原则**：智能体在**自主 "YOLO 模式"** 下运行，配备**扪心自问（FBR）**——通过战略性上下文重置和以任务为中心的专注架构，以干净的心理状态做出独立决策。

## 目录

1. [问题：智能体迷失方向](#问题智能体迷失方向)
2. [社会分工解决方案](#社会分工解决方案)
3. [扪心自问框架](#扪心自问框架)
4. [架构模式](#架构模式)
5. [实现细节](#实现细节)
6. [最佳实践](#最佳实践)
7. [未来方向](#未来方向)

---

## 问题：智能体迷失方向

### 核心问题：AI 智能体的认知过载

> LLM 智能体很容易迷失方向，远在技术上下文窗口完全填满之前

这个根本问题以几种方式表现：

**1. 上下文碎片化**

- 智能体在扩展交互中难以保持连贯的推理线索
- 重要的上下文被累积的对话历史埋没
- 决策质量随着对话长度增加而下降

**2. 注意力稀释**

- 智能体将认知资源分散到太多相互竞争的优先事项上
- 相关信息在过去交互的噪音中丢失
- 重点从主要目标转移到次要细节

**3. 心理状态退化**

- 智能体的"心理模型"变得混乱和不一致
- 之前的假设即使上下文已改变仍然存在
- 推理路径变得越来越复杂

### 为什么传统解决方案不够用

> 问题从来不是 token 太多，而是方面/关注点太多，它们像人类一样遭受心理过载

**Token 容量 vs. 认知容量**

- 尽管有大量的 token 限制，人类式的工作记忆限制仍然适用于 AI 智能体
- 推理质量在达到 token 限制之前很久就会下降
- 上下文窗口不是瓶颈——认知带宽才是

**多方面的注意力分散**

- 对话的每一程添加新的约束、目标和考虑因素
- 智能体必须保持对项目范围、用户偏好、技术约束等的认识
- 认知负荷随交互复杂性呈指数级增长

### 心理开销的来源

1. **对话噪音**
   - 重复的工具失败和错误消息
   - 调试尝试和诊断输出
   - 偏离核心目标的离题讨论
   - 冗余信息和循环对话

2. **上下文污染**
   - 累积的聊天历史掩盖当前优先事项
   - 与当前状态冲突的过时信息
   - 对话线索中信噪比混合

3. **注意力漂移**
   - 失去对主要任务目标的专注
   - 反应式而非战略性的思维模式
   - 跨对话参与者的碎片化心理模型

---

## 社会分工解决方案

### 上下文压缩：效果有限

> 上下文压缩？这对智能体迷失方向来说是一个相当糟糕的缓解措施

**上下文压缩实际做了什么**

- 将长对话历史总结为压缩形式
- 在减少 token 数量的同时保留关键事实
- 保持过去交互的"悬崖笔记"版本

**压缩方法的局限性**

**1. 信息丢失**

- 关键细微的上下文在摘要中丢失
- 重要决策推理消失
- 相似但不同场景之间的区别变得模糊

**2. 时间上下文问题**

- 压缩丢失推理顺序
- 因果关系变得混乱
- 对某些决策为何做出的理解恶化

**3. 静态 vs. 动态上下文**

- 摘要创建僵化的、过时的快照
- 应该演变的上下文变得石化
- 智能体失去对当前动态状态的意识

**4. 累积压缩损失**

- 每程压缩丢失更多信息
- 每次压缩循环准确度下降
- 最终变得适得其反

### 主动上下文管理：更好的方法

> 经常改变想法，经常清除脑海中的噪音

**核心哲学：AI 智能体的心理卫生**

**1. 有意的上下文重置**

- 定期"认知清理"会话
- 移除过时或无关的信息
- 通过主动修剪保持心智清晰

**2. 以任务为中心的专注架构**

- **中央差遣牒（Taskdoc）**：任务实时协调的公告板；目标/约束/进度的单一真实来源（关键决策与下一步必须写回 `progress`）
- **动态上下文窗口**：时间限制的上下文保留
- **基于优先级的信息过滤**：自动排名上下文相关性

术语：本文统一使用“差遣牒（Taskdoc）”指代任务契约与实时协调公告板；它不是个人草稿本。

### 差遣牒（Taskdoc）结构

```
差遣牒结构：
├── 目标
│   ├── 清晰的目标陈述
│   ├── 成功标准
│   └── 时间线约束
├── 进度
│   ├── 待处理的活跃决策
│   ├── 最近完成的项目
│   └── 立即下一步
└── 约束
    ├── 技术限制
    ├── 用户偏好
    └── 资源边界
```

### 以任务为中心的架构的好处

**1. 减少认知负荷**

- 智能体专注于一个中央文档
- 无需解析对话历史
- 当前任务和历史上下文之间清晰分离

**2. 提高决策质量**

- 所有决策的一致参考点
- 减少过时上下文的影响
- 更好地与用户意图对齐

**3. 增强适应性**

- 轻松在任务的不同方面之间转换
- 快速切换上下文而不丢失信息
- 跨会话保持连续性线索

### 战略实施模式

**模式 1：技术分析模式**

```
触发：需要复杂的技术决策
新鲜会话：
- 加载差遣牒（Taskdoc）+ 技术要求
- 专注："分析可行性并推荐方法"
- 输出：带有推理的清晰技术建议
```

**模式 2：创意构思模式**

```
触发：需要新想法或解决方案
新鲜会话：
- 仅加载差遣牒（Taskdoc）+ 问题陈述
- 专注："在不受约束偏见影响的情况下产生创新方法"
- 输出：带有理由的创意解决方案列表
```

**模式 3：质量保证模式**

```
触发：需要验证当前方法
新鲜会话：
- 加载差遣牒（Taskdoc）+ 当前解决方案尝试
- 专注："识别薄弱环节和改进机会"
- 输出：批判性分析和建议
```

## 扪心自问框架

### 初心概念（Fresh Boots）

> 让自己从推理中冥想出来，然后带着想法回到问题

**核心原则**：将一个"初心版本的自己"放入同一份任务上下文中，以干净的思维状态专注于问题的特定方面。

**传统 vs. 初心方法**

**传统问题解决：**

```
	智能体：[现有对话历史，当前状态，差遣牒] + 问题
→ 尝试同时解决所有方面
→ 遭受认知过载
→ 产生次优结果
```

**扪心自问（FBR）：**

```
	智能体：[干净的心理状态 + 仅差遣牒] + 特定子问题
→ 专注于单一方面
→ 应用不带包袱的新鲜推理
→ 产生清晰、有针对性的解决方案
→ 将洞察返回给主智能体
```

### 初心机制

**1. 子问题隔离**

- 将复杂问题分解为特定的、有界的子问题
- 为新鲜推理会话创建详细提示
- 确保子问题真正独立

**2. 新上下文创建**

- 将智能体的"心理状态"重置为初始任务理解
- 仅加载必要的差遣牒和子问题
- 清除所有累积的对话上下文

**3. 专注推理会话**

- 智能体以全部认知带宽攻击子问题
- 没有其他任务方面的干扰
- 纯粹的问题解决，没有上下文污染

**4. 结果整合**

- 从新鲜推理中提取关键洞察
- 将发现整合回主要任务上下文
- 保持洞察和上下文之间的清晰分离

### 高级初心策略

#### 多透镜方法

**概念**：使用不同的"透镜"或视角来检查同一个问题，每个都有新鲜的智能体实例。

**实现：**

1. **分析透镜**：纯逻辑和数据驱动分析
2. **创意透镜**：创新和跳出思维定式
3. **批判透镜**：怀疑性评估和假设测试
4. **用户中心透镜**：关注最终用户体验和价值

#### 渐进精炼周期

**阶段 1：初始初心**

- 使用干净的推理生成第一遍解决方案
- 不考虑约束的情况下捕获原始洞察

**阶段 2：约束应用**

- 第二个新鲜会话应用现实世界约束
- 将任务要求与初始洞察整合

**阶段 3：质量验证**

- 第三个新鲜会话评估完整解决方案
- 识别潜在问题和改进机会

#### 会话层次：元新鲜推理

**概念**：有时即使是“回到初心”的推理也需要刷新。

**新鲜度级别：**

1. **级别 0**：当前智能体状态
2. **级别 1**：干净智能体 + 差遣牒（Taskdoc）（标准初心）
3. **级别 2**：完全重置的智能体，只有问题陈述
4. **级别 3**：具有不同训练重点的新智能体实例

### Dominds 中的扪心自问（FBR）实现

**自主触发：**

- 智能体检测认知过载何时影响性能
- 自主发起的复杂子问题新鲜推理会话
- 自动会话管理和结果整合

**以任务为中心的新鲜会话：**

- 所有新鲜推理会话引用相同的中央差遣牒（Taskdoc）
- 确保多个专注推理尝试的一致性
- 允许认知重置的同时保持连续性线索

**多智能体新鲜协调：**

- 不同智能体可以从不同角度对同一问题运行新鲜会话
- 并行新鲜推理加速复杂问题解决
- 结果自动整合到共享任务上下文中

---

## 架构模式

### 对话层次结构

```
主对话（根对话）
├── 差遣牒引用 → tasks/feature-auth.tsk/（rtws 任务包）
├── 提醒项（工作记忆）
├── 聊天消息（临时）
└── 子对话（树结构，扁平存储在主对话下）
    ├── 专业智能体 A
    │   ├── 差遣牒引用 → tasks/feature-auth.tsk/（相同的任务包）
    │   ├── 父调用上下文
    │   ├── 本地提醒项
    │   └── 本地聊天消息
    │   └── 子子对话（可进一步嵌套）
    └── 专业智能体 B
        ├── 差遣牒引用 → tasks/feature-auth.tsk/（相同的任务包）
        ├── 父调用上下文
        ├── 本地提醒项
        └── 本地聊天消息
```

**关键属性：**

- 所有对话引用相同的 rtws 差遣牒（一个 `*.tsk/` 任务包，例如 `tasks/feature-auth.tsk/`）
- 多个对话树可以引用相同的差遣牒进行协作工作
- 差遣牒超越单个对话持续存在并经历团队变化
- 子对话可以是具有无限嵌套深度的树结构
- 所有子对话状态扁平存储在主对话的 `subdialogs/` 目录下
- 每个子对话在引用相同差遣牒的同时维护自己的工作记忆

### 记忆层

#### 对话范围记忆（每个对话）

1. **差遣牒引用**：指向跟踪特定 DevOps 任务的 rtws 差遣牒
   - `*.tsk/` 任务包（`goals.md`、`constraints.md`、`progress.md`）
   - 多个对话可以引用相同的差遣牒进行协作工作
   - 差遣牒在整个产品生命周期中持续存在，跨越多个对话和团队变化
   - 可以链接到其他产品文档并随项目要求演变
2. **提醒项**：半持久化、对话范围，在对话清理中存活
3. **父调用上下文**：子对话继承的上下文
4. **聊天消息**：临时，受清理以保持心理清晰

#### rtws 持久化记忆（DevOps 生命周期）

5. **团队共享记忆**：在整个项目生命周期中持久化
   - **任务上下文**：项目目标和约束的共享理解
   - **集体知识**：团队积累的见解、模式和经验教训
   - **共享标准**：编码约定、架构决策和最佳实践
   - **项目历史**：重要决策、里程碑和上下文演变

6. **智能体个体记忆**：跨所有对话每个智能体持久化的个人知识
   - **个人专长**：个体智能体的专业知识和技能
   - **个人经验**：个人学习和适应模式
   - **角色特定上下文**：智能体特定职责和操作知识
   - **性能模式**：个人优化策略和偏好

**记忆特征：**

- **透明度**：所有记忆对人类透明并可通过人类监督调整
- **自主演进**：记忆由智能体团队随时间自主持续改进
- **生命周期持久性**：团队和智能体记忆在整个 DevOps 生命周期中持久化
- **人类可访问性**：人类可以随时检查、修改和指导记忆演进

### 信息流

- **向上**：子对话向父级传达结果和升级
- **向下**：父级向子对话提供上下文和目标
- **横向**：通过共享差遣牒和父级调解进行协调
- **时间性**：提醒项和差遣牒提供跨时间的连续性

---

## 实现

有关核心工具、技术架构和系统行为的详细实现规范，请参阅[对话系统实现](dialog-system.md)文档。

**关键实现组件：**

- **`clear_mind`**：开启新一程对话的函数工具（用于清除对话噪音）
- **`change_mind`**：用于跨对话层次结构更新权威差遣牒的函数工具（不会开启新一程对话）
- **提醒项管理**：跨清理操作持续存在的对话范围工作记忆
- **层次对话架构**：具有扁平存储和自主管理的树结构对话
- **记忆层**：具有自主演进的对话范围和 rtws 持久化记忆

该实现强调自主智能体操作，使智能体能够独立管理其认知状态、创建和管理子对话，并在最少的人工监督下进行协调。

---

## 最佳实践和指南

### 何时使用扪心自问（FBR）

**最佳场景：**

- 复杂的多方面问题
- 需要新视角的决策点
- 创意构思需求
- 质量保证和验证
- 突破分析瘫痪

**何时避免：**

- 简单直接的任务
- 需要与先前工作连续性的情况
- 实时交互任务
- 紧急响应场景

### 会话设计原则

**1. 具体性**

- 定义确切的子问题范围
- 每个会话的清晰成功标准
- 避免模糊或开放式提示

**2. 完整性**

- 确保提供所有必要的上下文
- 包括相关的约束和要求
- 提供所需的任何先决知识

**3. 独立性**

- 设计子问题是自包含的
- 最小化会话之间的依赖关系
- 可能时允许并行处理

### 衡量有效性

**关键指标：**

1. **解决方案质量**：新鲜推理是否产生更好的结果？
2. **速度**：洞察生成有多快？
3. **一致性**：结果在会话之间可重现吗？
4. **效率**：与传统方法相比的资源利用

**成功指标：**

- 每个会话产生清晰、可操作的洞察
- 更好地与用户需求对齐
- 减少问题解决时间
- 最终解决方案质量更高

### 对于以自主模式运行的 AI 智能体

#### 主动清晰度管理

1. **自我导向清晰度评估**：定期评估自己的认知负荷和对话噪音水平，无需等待外部提示

2. **差遣牒专注**：在做出自主决策或改变方向时，始终将差遣牒作为主要真实来源

3. **战略清晰时机**：当你检测到对话噪音正在影响你的自主决策质量时，触发 `clear_mind`

4. **独立上下文保留**：在任何清晰操作之前，通过结构化提醒项自主评估和保留基本上下文

#### 扪心自问（FBR）实施

- **自我监控**：持续评估自己的认知状态和对话质量，无需外部提示
- **早期自主干预**：当你检测到注意力碎片化时，独立触发新鲜推理会话，不要等到累积压倒性
- **模式识别**：学会自主识别认知过载的信号（重复失败、循环讨论、失去焦点）
- **战略自主时机**：利用工作中的自然断点进行自我导向的新鲜推理操作

### 对于系统设计师

#### 架构原则

1. **自主优先架构**：设计使能并鼓励自主智能体行为而非需要持续人工监督的系统

2. **自我管理工具**：为智能体提供支持自主认知状态管理和决策的工具和模式

3. **清晰的自主边界**：建立清晰的运营边界，允许智能体独立运行同时保持系统一致性

4. **自主反馈循环**：设计智能体可以自主评估自己的绩效并相应调整行为的系统

5. **独立协调模式**：创建无需中央控制即可工作的协调机制，实现自主多智能体协作

---

## 差遣牒示例

### 示例差遣牒结构

差遣牒是一个封装的 `*.tsk/` 任务包，跟踪特定的 DevOps 任务：

```
tasks/auth-system.tsk/
├── goals.md
├── constraints.md
└── progress.md
```

示例内容：

- `goals.md`："使用 JWT 令牌和基于角色的访问控制实现安全用户身份验证。"
- `constraints.md`："必须支持邮箱/密码身份验证；必须实现 JWT 刷新；必须添加基于角色的权限……"
- `progress.md`：清单/状态注释（快速变化）。

### 差遣牒生命周期

**创建阶段：**

```bash
# 创建新差遣牒
mkdir -p tasks
mkdir -p tasks/auth-system.tsk
echo "# Feature: User Authentication" > tasks/auth-system.tsk/goals.md

# 启动引用差遣牒的对话
dominds dialog start --taskdoc-path tasks/auth-system.tsk
```

**开发阶段：**

- 多个对话树可以引用相同的差遣牒
- 团队成员通过 `change_mind` 操作更新相同的差遣牒进行协作
- 进度跟踪跨越对话持续存在
- 要求通过 `change_mind` 操作演变
- rtws 硬性规则：
  - `*.tsk/**` 是封装的差遣牒状态，所有通用文件工具都硬性拒绝。
  - `.minds/**` 是保留的 rtws 状态（团队配置/内存/资产），所有通用文件工具都硬性拒绝；通过 `team-mgmt` 等专用工具进行管理。

**协作示例：**

```yaml
# 对话 A（后端专家）
taskdoc: "tasks/auth-system.tsk"
focus: "JWT 令牌服务实现"

# 对话 B（前端专家）
taskdoc: "tasks/auth-system.tsk"
focus: "登录 UI 集成"

# 对话 C（DevOps 专家）
taskdoc: "tasks/auth-system.tsk"
focus: "部署和监控设置"
```

**长期演变：**

- 差遣牒经历团队变化
- 跨越 rtws 重组保持持久
- 维护要求演变的历史
- 支持多个并行开发工作
- 参考其他演变中的产品文档

### 多任务 rtws 示例

```
rtws/
├── tasks/
│   ├── auth-system.tsk/          # 身份验证功能
│   ├── payment-integration.tsk/  # 支付处理
│   ├── mobile-app.tsk/           # 移动应用
│   └── performance-opt.tsk/      # 性能优化
├── specs/
│   ├── api-design.md
│   └── ui-mockups.md
└── docs/
    ├── architecture.md
    └── deployment.md
```

每份差遣牒代表一个独立的 DevOps 任务，可以并行处理；多个对话树在保持各自对话上下文的同时就相同目标进行协作。

---

## 未来方向

### 增强自主能力

- **高级自我评估**：开发更复杂的自主认知负荷评估算法
- **预测性清晰度管理**：使智能体能够预测何时需要清晰操作并主动准备
- **自主学习**：允许智能体根据自己的性能模式学习和调整清晰度策略
- **自优化层次结构**：使对话层次结构能够自主重组以获得最佳性能

### 自主多智能体协调

- **分布式自主共识**：开发自主智能体就任务方向变化达成共识的协议
- **自组织智能体网络**：使智能体能够根据任务要求自主形成和解散协作网络
- **独立冲突解决**：创建无需人工干预的自主智能体解决冲突的机制

### 高级自主上下文管理

- **智能自主上下文压缩**：开发智能体自主压缩和保留基本上下文的算法
- **自我导向上下文共享**：使智能体能够自主确定跨对话边界共享什么上下文
- **自主记忆优化**：允许智能体独立优化其记忆使用和保留策略

### 研究机会

#### 自主认知负荷指标

- **自我评估算法**：智能体评估自己认知状态和决策质量的定量措施
- **性能相关性**：自主上下文质量与独立任务绩效之间的关系
- **最优自主清晰时机**：研究智能体应独立触发清晰操作以获得最大益处的时机

#### 自主多智能体协作

- **独立协调**：自主智能体如何在没有中央控制的情况下有效协调
- **自组织心理模型**：自主智能体在无需显式同步的情况下保持一致理解的技术
- **自主信任网络**：在自主智能体决策中建立信心和可靠性

#### 可扩展性和自主性能

- **大规模自主对话管理**：具有数百个独立运行对话的系统的清晰度策略
- **自优化记忆**：在保持上下文质量的同时自主优化记忆使用
- **独立实时操作**：最小化自主清晰度操作中的延迟以实现响应系统

---

## 结论

AI 智能体有效性的未来不在于更大的上下文窗口，而在于更智能的上下文管理。通过拥抱主动上下文清除和扪心自问（FBR）等概念，我们可以构建在扩展交互中保持清晰和专注的智能体。

AI 智能体的社会分工代表了从传统单体方法到认知架构的根本转变。dominds 系统表明，系统化的心理清晰实践不仅仅是锦上添花的功能，而是实现自主、高效和可靠 AI 辅助的核心架构原则。

关键洞察是，AI 智能体和人类一样，从心理卫生实践中受益匪浅。定期的认知清理和专注的问题解决会话可以显著提高智能体推理的质量和效率。扪心自问（FBR）将管理大量对话上下文的挑战转化为优势，允许智能体通过中央差遣牒保持整体项目连续性的同时，对复杂问题的每个方面带来新鲜、专注的注意力。

随着 AI 系统变得更加复杂并部署在更具挑战性的环境中，本文中概述的原则和模式对于成功将变得越来越重要。未来属于能够清晰思考、自主运行并通过系统化认知管理方法有效协作的 AI 智能体。
